import os
import json
import time
from pathlib import Path
from dotenv import load_dotenv
from moviepy import VideoFileClip
from mistralai import Mistral

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def extract_audio(video_path: Path, audio_path: Path):
    """å¾å½±ç‰‡æå–éŸ³è¨Šä¸¦å„²å­˜ç‚º mp3"""
    print(f"æ­£åœ¨å¾ {video_path.name} æå–éŸ³è¨Š...")
    video = VideoFileClip(str(video_path))
    video.audio.write_audiofile(str(audio_path), logger=None)
    video.close()
    print(f"éŸ³è¨Šå·²æå–è‡³ {audio_path}")

def transcribe_with_mistral(client: Mistral, audio_path: Path):
    """
    å‘¼å« Mistral API é€²è¡Œè½‰éŒ„ï¼Œå–å¾—å¸¶æ™‚é–“è»¸çš„ segmentã€‚
    """
    print(f"æ­£åœ¨å‘¼å« Mistral API é€²è¡Œè½‰éŒ„...")
    with open(audio_path, "rb") as f:
        response = client.audio.transcriptions.complete(
            model="voxtral-mini-latest",
            file={
                "content": f.read(),
                "file_name": audio_path.name
            },
            timestamp_granularities=["segment"]
        )
    return response

def load_terms(video_name: str = ""):
    """
    è¼‰å…¥å¤–éƒ¨å­—è©åº«ï¼Œä¾å½±ç‰‡åç¨±è‡ªå‹•åŒ¹é…å°æ‡‰çš„å­—è©çµ„ã€‚
    åŒ¹é…é‚è¼¯ï¼šæª¢æŸ¥ terms.json ä¸­çš„ key æ˜¯å¦å‡ºç¾åœ¨å½±ç‰‡æª”åä¸­ã€‚
    è‹¥ç„¡åŒ¹é…å‰‡ä½¿ç”¨ 'default'ã€‚
    """
    terms_path = Path("terms.json")
    if not terms_path.exists():
        return {"corrections": {}, "key_terms": [], "topic_hint": ""}
    
    with open(terms_path, "r", encoding="utf-8") as f:
        all_terms = json.load(f)
    
    # ä¾å½±ç‰‡åç¨±åŒ¹é…å­—è©åº«
    for key, terms in all_terms.items():
        if key == "default":
            continue
        if key in video_name:
            print(f"å­—è©åº«åŒ¹é…ï¼šã€Œ{key}ã€")
            return terms
    
    # ç„¡åŒ¹é…å‰‡ç”¨ default
    print("å­—è©åº«åŒ¹é…ï¼šä½¿ç”¨é è¨­ (default)")
    return all_terms.get("default", {"corrections": {}, "key_terms": [], "topic_hint": ""})

def process_and_summarize(client: Mistral, transcription_response, video_name: str = ""):
    """
    ä½¿ç”¨ Mistral Chat API å°é€å­—ç¨¿é€²è¡Œï¼š
    1. ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡
    2. ä¾å­—è©åº«æ ¡æ­£å°ˆæœ‰åè©
    3. ç¯©é¸ã€Œé—œéµçŸ¥è­˜é» (Key Knowledge Points)ã€
    4. ç‚ºæ¯å€‹çŸ¥è­˜é»ç”¢ç”Ÿæ¨™é¡Œ
    5. ç”¢ç”Ÿå…§å®¹æ‘˜è¦
    """
    print("æ­£åœ¨è™•ç†æ–‡æœ¬ï¼šç¿»è­¯ã€æ ¡æ­£å°ˆæœ‰åè©ä¸¦ç¯©é¸é—œéµçŸ¥è­˜é»...")
    
    terms = load_terms(video_name)
    
    segments = transcription_response.segments
    text_to_process = "\n".join([f"[{s.start}-{s.end}] {s.text}" for s in segments])
    
    # å‹•æ…‹çµ„è£å­—è©åº«æç¤º
    terms_section = ""
    if terms.get("topic_hint"):
        terms_section += f"- æœ¬å½±ç‰‡ä¸»é¡Œï¼š{terms['topic_hint']}\n"
    if terms.get("corrections"):
        correction_rules = "ã€".join([f"ã€Œ{k}ã€â†’ã€Œ{v}ã€" for k, v in terms["corrections"].items()])
        terms_section += f"- åè©æ ¡æ­£è¦å‰‡ï¼š{correction_rules}\n"
    if terms.get("key_terms"):
        terms_section += f"- é ˜åŸŸé—œéµè©å½™ï¼š{', '.join(terms['key_terms'])}\n"
    
    prompt = f"""
ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„å½±éŸ³é€å­—ç¨¿ç¿»è­¯èˆ‡æ•™å­¸é‡é»æ‘˜è¦å°ˆå®¶ã€‚
è«‹å°‡ä»¥ä¸‹å¸¶æœ‰æ™‚é–“è»¸çš„é€å­—ç¨¿å…§å®¹é€²è¡Œç²¾ç…‰è™•ç†ã€‚

### åŸå§‹é€å­—ç¨¿å…§å®¹ï¼š
{text_to_process}

### å­—è©åº«èˆ‡å°ˆæ¥­è¡“èªåƒè€ƒï¼š
{terms_section}

### é‡è¦ä»»å‹™èˆ‡è¦æ±‚ï¼š
1. **ç¿»è­¯èˆ‡æ ¡æ­£**ï¼šå°‡æ‰€æœ‰å…§å®¹ç¿»è­¯ç‚ºã€Œç¹é«”ä¸­æ–‡ã€ã€‚è«‹åš´æ ¼ä¾ç…§ä¸Šæ–¹ã€Œåè©æ ¡æ­£è¦å‰‡ã€ä¿®æ­£éŒ¯èª¤ç”¨è©ã€‚
2. **ç¯©é¸é‡é»**ï¼šåŸå§‹å…§å®¹å¯èƒ½åŒ…å«éå¤šé›¶ç¢çš„å°è©±æˆ–é›œè¨Šã€‚è«‹å¾ä¸­æŒ‘é¸å‡ºã€ŒçœŸæ­£çš„é—œéµçŸ¥è­˜é» (Key Knowledge Points)ã€ã€‚
3. **æ‘˜è¦**ï¼šæä¾›ä¸€ä»½æ•´é«”çš„ç¹é«”ä¸­æ–‡å…§å®¹æ‘˜è¦ã€‚
4. **è¼¸å‡ºæ ¼å¼**ï¼šå¿…é ˆç‚º JSONã€‚
5. **JSON çµæ§‹**ï¼š
{{
  "summary": "é€™è£¡å¡«å¯«æ•´é«”çš„ç¹é«”ä¸­æ–‡æ‘˜è¦",
  "key_moments": [
    {{
      "title": "æ­¤æ®µè½çš„ç²¾ç°¡æ¨™é¡Œï¼ˆ5-15å­—ï¼‰",
      "start": 0.0,
      "end": 10.5,
      "text": "ç¿»è­¯ä¸¦æ ¡æ­£å¾Œçš„ç¹é«”ä¸­æ–‡å…§å®¹"
    }},
    ...
  ]
}}
6. **æº–å‰‡**ï¼š
   - è«‹å°‡é„°è¿‘ä¸”ä¸»é¡Œç›¸åŒçš„ segment åˆä½µç‚ºä¸€å€‹ key_momentï¼Œç¢ºä¿ç¸½æ•¸é‡é©ä¸­ï¼ˆå»ºè­° 5-15 å€‹ï¼‰ã€‚
   - æ¯å€‹ key_moment å¿…é ˆæœ‰ä¸€å€‹ç²¾ç°¡çš„ã€Œtitleã€æ¬„ä½ï¼Œç”¨ä¸€å¥è©±æ¦‚æ‹¬è©²æ®µè½çš„æ ¸å¿ƒçŸ¥è­˜é»ã€‚

è«‹åªè¿”å› JSON å…§å®¹ã€‚
"""

    chat_response = client.chat.complete(
        model="mistral-large-latest",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0
    )
    
    return json.loads(chat_response.choices[0].message.content)

def capture_screenshots(video_path: Path, segments: list, screenshot_dir: Path):
    """
    é‡å°æ¯å€‹ key_moment æ“·å–æœ€å…·ä»£è¡¨æ€§çš„ç•«é¢ã€‚
    ç­–ç•¥ï¼šåœ¨æ¯å€‹æ™‚é–“æ®µå…§å–å¤šå€‹å€™é¸å¹€ï¼Œé¸å–ã€Œè¦–è¦ºå…§å®¹æœ€è±å¯Œã€çš„ä¸€å¹€ã€‚
    """
    print(f"æ­£åœ¨æ™ºæ…§æ“·å–æˆªåœ–è‡³ {screenshot_dir}...")
    if screenshot_dir.exists():
        import shutil
        shutil.rmtree(screenshot_dir)
    screenshot_dir.mkdir(parents=True, exist_ok=True)
    
    video = VideoFileClip(str(video_path))
    
    screenshot_paths = []
    for i, seg in enumerate(segments):
        start = seg['start']
        end = seg['end']
        duration = end - start
        
        # åœ¨æ®µè½å…§å–å¤šå€‹å€™é¸æ™‚é–“é» (æœ€å¤š 5 å€‹)
        num_candidates = min(5, max(2, int(duration / 3)))
        candidate_times = []
        for k in range(num_candidates):
            t = start + duration * (k + 1) / (num_candidates + 1)
            t = min(t, video.duration - 0.1)
            candidate_times.append(t)
        
        # å–å¾—æ‰€æœ‰å€™é¸å¹€ä¸¦è¨ˆç®—è¦–è¦ºè±å¯Œåº¦ (ç”¨åƒç´ æ¨™æº–å·®)
        best_time = candidate_times[0]
        best_score = -1
        
        for t in candidate_times:
            frame = video.get_frame(t)
            # è¨ˆç®—åƒç´ æ¨™æº–å·® â€” è¶Šé«˜ä»£è¡¨ç•«é¢ç´°ç¯€è¶Šè±å¯Œï¼Œè¶Šä¸åƒç´”è‰²/è½‰å ´
            import numpy as np
            score = float(np.std(frame))
            if score > best_score:
                best_score = score
                best_time = t
        
        screenshot_filename = f"key_{i:03d}.jpg"
        screenshot_path = screenshot_dir / screenshot_filename
        video.save_frame(str(screenshot_path), t=best_time)
        screenshot_paths.append(screenshot_filename)
        print(f"  [{i+1}/{len(segments)}] {seg.get('title', '')} -> {best_time:.1f}s (score: {best_score:.1f})")
        
    video.close()
    return screenshot_paths

def generate_html(video_name: str, summary: str, segments: list, screenshot_paths: list, output_html_path: Path):
    """
    ç”ŸæˆåŒ…å«æ‘˜è¦ã€é—œéµçŸ¥è­˜é»èˆ‡æˆªåœ–çš„ HTML å ±å‘Š
    """
    print(f"æ­£åœ¨ç”Ÿæˆå„ªåŒ–å¾Œçš„ HTML å ±å‘Š: {output_html_path.name}...")
    
    rows_html = ""
    for i, (seg, img_name) in enumerate(zip(segments, screenshot_paths)):
        safe_img_path = f"screenshots/{video_name.replace(' ', '_')}/{img_name}"
        title = seg.get('title', f'çŸ¥è­˜é» {i+1}')
        rows_html += f"""
        <div class="segment">
            <div class="segment-image">
                <img src="{safe_img_path}" alt="{title}">
            </div>
            <div class="segment-content">
                <div class="segment-title">{title}</div>
                <div class="timestamp">{seg['start']:.1f}s - {seg['end']:.1f}s</div>
                <div class="segment-text">
                    {seg['text']}
                </div>
            </div>
        </div>
        """
    
    html_content = f"""
<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>å½±ç‰‡çŸ¥è­˜é»å ±å‘Š - {video_name}</title>
    <style>
        body {{ font-family: 'Noto Sans TC', sans-serif, 'Segoe UI'; line-height: 1.6; color: #333; max-width: 1000px; margin: 0 auto; padding: 30px; background-color: #f8f9fa; }}
        h1 {{ color: #1a2a6c; text-align: center; margin-bottom: 30px; font-size: 2.2em; }}
        .summary-box {{ background: #ffffff; padding: 25px; border-radius: 12px; box-shadow: 0 4px 15px rgba(0,0,0,0.05); margin-bottom: 40px; border-top: 6px solid #b21f1f; }}
        .summary-title {{ font-weight: bold; font-size: 1.4em; margin-bottom: 15px; color: #b21f1f; display: flex; align-items: center; }}
        .summary-title::before {{ content: 'ğŸ“'; margin-right: 10px; }}
        .segment {{ display: flex; background: white; margin-bottom: 30px; border-radius: 12px; overflow: hidden; box-shadow: 0 4px 12px rgba(0,0,0,0.08); transition: transform 0.2s; }}
        .segment:hover {{ transform: translateY(-3px); }}
        .segment-image {{ flex: 0 0 350px; overflow: hidden; border-right: 1px solid #eee; }}
        .segment-image img {{ width: 100%; height: 100%; object-fit: cover; display: block; }}
        .segment-content {{ padding: 20px; flex: 1; display: flex; flex-direction: column; justify-content: start; }}
        .segment-title {{ font-size: 1.25em; font-weight: bold; color: #1a2a6c; margin-bottom: 6px; }}
        .timestamp {{ color: #888; font-size: 0.82em; margin-bottom: 12px; }}
        .segment-text {{ font-size: 1.05em; line-height: 1.7; color: #444; }}
        @media (max-width: 768px) {{
            .segment {{ flex-direction: column; }}
            .segment-image {{ flex: 0 0 auto; }}
        }}
    </style>
</head>
<body>
    <h1>å½±ç‰‡çŸ¥è­˜é»è©³ç´°å ±å‘Š</h1>
    <div style="text-align: center; margin-bottom: 20px; color: #666;">
        <strong>æª”å:</strong> {video_name}
    </div>
    
    <div class="summary-box">
        <div class="summary-title">å…§å®¹è¦é»ç¸½çµ</div>
        <div style="font-size: 1.1em;">{summary}</div>
    </div>

    <div class="segments-container">
        {rows_html}
    </div>
    
    <footer style="text-align: center; padding: 40px; color: #888; font-size: 0.9em;">
        Generated by Mistral AI Video Analyzer
    </footer>
</body>
</html>
"""
    with open(output_html_path, "w", encoding="utf-8") as f:
        f.write(html_content)

def main():
    api_key = os.getenv("MISTRAL_API_KEY")
    if not api_key or api_key == "your_api_key_here":
        print("éŒ¯èª¤ï¼šè«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®š MISTRAL_API_KEY")
        return

    client = Mistral(api_key=api_key)
    
    video_dir = Path("Video")
    output_base_dir = Path("output")
    temp_dir = Path("temp_audio")
    
    output_base_dir.mkdir(exist_ok=True)
    temp_dir.mkdir(exist_ok=True)
    
    video_extensions = [".mp4", ".mkv", ".mov", ".avi"]
    videos = [f for f in video_dir.iterdir() if f.suffix.lower() in video_extensions]
    
    if not videos:
        print(f"åœ¨ {video_dir} ç›®éŒ„ä¸‹æ‰¾ä¸åˆ°å½±ç‰‡æª”æ¡ˆã€‚")
        return

    for video_path in videos:
        print(f"\n--- é–‹å§‹è™•ç†å½±ç‰‡: {video_path.name} ---")
        
        json_file = output_base_dir / f"{video_path.stem}_transcription.json"
        
        # å¿«å–æ©Ÿåˆ¶ï¼šå¦‚æœ JSON å·²å­˜åœ¨ï¼Œè·³éè½‰éŒ„èˆ‡ç¿»è­¯ï¼Œåªé‡æ–°ç”Ÿæˆæˆªåœ–èˆ‡ HTML
        if json_file.exists():
            print(f"åµæ¸¬åˆ°å·²æœ‰å¿«å– JSON: {json_file.name}")
            print("è·³éè½‰éŒ„èˆ‡ç¿»è­¯ï¼Œç›´æ¥ä½¿ç”¨å¿«å–è³‡æ–™é‡æ–°ç”Ÿæˆæˆªåœ–èˆ‡ HTML...")
            with open(json_file, "r", encoding="utf-8") as f:
                processed_data = json.load(f)
        else:
            # 1. æå–éŸ³è¨Š
            audio_path = temp_dir / f"{video_path.stem}.mp3"
            extract_audio(video_path, audio_path)
            
            try:
                # 2. è½‰éŒ„
                transcription = transcribe_with_mistral(client, audio_path)
                
                # 3. ç¿»è­¯èˆ‡ç¯©é¸é‡é» (JSON)
                processed_data = process_and_summarize(client, transcription, video_path.name)
                
                # å„²å­˜ JSONï¼ˆä½œç‚ºå¿«å–ï¼‰
                with open(json_file, "w", encoding="utf-8") as f:
                    json.dump(processed_data, f, ensure_ascii=False, indent=2)
                print(f"JSON å·²å„²å­˜ï¼ˆä½œç‚ºå¿«å–ï¼‰: {json_file}")
                
            except Exception as e:
                print(f"è™•ç†å½±ç‰‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                import traceback
                traceback.print_exc()
                continue
            finally:
                if audio_path.exists():
                    audio_path.unlink()
        
        try:
            # 4. è‡ªå‹•æˆªåœ– (åƒ…é™é—œéµçŸ¥è­˜é»)
            safe_video_name = video_path.name.replace(' ', '_')
            screenshot_dir = output_base_dir / "screenshots" / safe_video_name
            screenshot_paths = capture_screenshots(video_path, processed_data["key_moments"], screenshot_dir)
            
            # 5. ç”Ÿæˆ HTML å ±å‘Š
            html_file = output_base_dir / f"{video_path.stem}_report_v2.html"
            generate_html(
                video_path.name, 
                processed_data["summary"], 
                processed_data["key_moments"], 
                screenshot_paths, 
                html_file
            )
            
            print(f"å®Œæˆï¼")
            print(f"JSON çµæœ: {json_file}")
            print(f"HTML å ±å‘Š: {html_file}")
            
        except Exception as e:
            print(f"ç”Ÿæˆæˆªåœ–æˆ– HTML æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()
